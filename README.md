<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Summer Research Intership 2022</title><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 h1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 16pt; }
 h2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 14pt; }
 h3 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: underline; font-size: 12pt; }
 .s1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 .p, p { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; margin:0pt; }
 h4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .s2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s3 { color: #00F; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s7 { color: black; font-family:"Nirmala UI", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l1 {padding-left: 0pt;counter-reset: c1 1; }
 #l1> li:before {counter-increment: c1; content: counter(c1, upper-roman)". "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l1> li:first-child:before {counter-increment: c1 0;  }
 #l2 {padding-left: 0pt; }
 #l2> li:before {content: "- "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l3 {padding-left: 0pt; }
 #l3> li:before {content: "- "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 #l4 {padding-left: 0pt; }
 #l4> li:before {content: "● "; color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="116" height="89" alt="image" src="Summer Research Intership 2022/Image_001.png"/></span></p><h1 style="padding-top: 11pt;padding-left: 209pt;text-indent: -96pt;line-height: 133%;text-align: left;">Indian Institute of Information Technology, Vadodara (Gandhinagar Campus)</h1><h2 style="padding-left: 185pt;text-indent: 0pt;line-height: 16pt;text-align: left;">Summer Research Internship - 2022</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 4pt;padding-left: 33pt;text-indent: 0pt;text-align: center;">E<span class="s1"> </span>xtraction of melodies with pitch classes From images of HCM compositions in Bhatkhande notation</h3><p style="padding-top: 6pt;padding-left: 33pt;text-indent: 0pt;text-align: center;">under the mentorship of</p><h4 style="padding-left: 33pt;text-indent: 0pt;text-align: center;">Dr.Pratik Shah</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: center;">Submitted by</p><h4 style="padding-left: 33pt;text-indent: 0pt;text-align: center;">Manjot Singh (201951090)</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="372" height="497" alt="image" src="Summer Research Intership 2022/Image_002.jpg"/></span></p><h4 style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="https://github.com/mickee00000/201951090_Research_Internship_2022" style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt;" target="_blank">Abstract - Conversion of Music Notes from images of Bhatkhande Notation System into MIDI file(audio file) involving Images Processing using OpenCV, Deep convolutional neural network modeling using Tensorflow and Keras and extracting those notes to be converted into a playable audio file using music21 toolkit for computer-aided musicology. The source code and other involved files for this project can be found </a><span style=" color: #1154CC; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: bold; text-decoration: underline; font-size: 10pt;">here</span>.</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l1"><li style="padding-top: 7pt;padding-left: 136pt;text-indent: -41pt;text-align: left;"><p style="display: inline;">I<span class="s2">NTRODUCTION</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">The Indian Classical Music holds a very high place in our Indian culture, to the point that it is synonymous to Indian festivals, religious customs, marriages, exotic cuisine and Traditional Clothing. Doesn’t matter who you are or what part of India you belong to, the minute you hear Indian music, the nostalgia and the amusement kicks in. Even if you are not from India, it would still create a sense of elegance and simplistic pleasures.</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">But despite its legendary status in the music culture, it seems that it is not being practiced heavily by the masses. Part of the reason is that it is less accessible and not being able to be visualized from reading about it in books and online articles. We are living in the age of social media and Short Clips platforms which tend to cause low attention span. “TikTok use disorder (TTUD) is positively linked to memory loss, and it is also positively linked to depression, anxiety, and stress. Depression, anxiety,  and stress are positively linked to memory loss. Furthermore, depression, anxiety,  and stress have a mediating effect between TTUD and memory loss.” <span style=" color: #00F;">[1]</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">This project tries to bridge that gap between written medium and being able to hear and picture the beauty of the melodies. To be able to just convert your favorite melodies instantly from unexciting texts in your old books to audio files in your phone or laptop almost seems like a dream come true for a music enthusiast.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 122pt;text-indent: -40pt;text-align: left;"><p style="display: inline;">P<span class="s2">ROBLEM </span>S<span class="s2">TATEMENT</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Now that we understand the importance of the project, we need to understand and break down what are the necessary steps we need to take to solve this problem.</p><p class="s4" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"> Task<span class="p">: From images of HCM compositions in Bhatkhande notation, extract the melodies with pitch classes.</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">So, initially this image needs to be converted into a supported audio file.</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">After that, contours(outline along the boundary) of the image are detected, extracted and drawn onto another blank image.</p></li><li style="padding-top: 8pt;padding-left: 124pt;text-indent: -42pt;text-align: left;"><p style="display: inline;">P<span class="s2">ROPOSED </span>S<span class="s2">OLUTION</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">A lot of approaches had to be considered for this project. The final approach ended up being diving this task into 3 parts:</p><ul id="l2"><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;">NOTATION RECOGNITION AND PROCESSING</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;">NOTATION CLASSIFICATION</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;">AUDIO EXTRACTION</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">Or in simpler terms, this is divided as:</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;">What to read in this image?</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;">What is the meaning of the part that I just read in the image?</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;">What sound to produce in response to what I just read.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"> <b>PART A</b><b> - </b><span class="p">NOTATION RECOGNITION AND PROCESSING</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="280" height="460" alt="image" src="Summer Research Intership 2022/Image_003.jpg"/></span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">For this, OpenCV is used to convert the notation image to a data array of the image. First comes Preprocessing of the image in which all the extra noise on the image is removed, like the color of the paper,  different shades of color etc, so that it would not interfere with the detection. After this we end up with a binary version of the image where only two colors exist, Black (0,0,0) and White(255,255,255).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="372" height="497" alt="image" src="Summer Research Intership 2022/Image_004.jpg"/></span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Using these contours, Bounding Rectangles are drawn on the</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">co-ordinates of these contours and saved on another blank image.</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span><img width="372" height="495" alt="image" src="Summer Research Intership 2022/Image_005.jpg"/></span>	<span><img width="372" height="495" alt="image" src="Summer Research Intership 2022/Image_006.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">After getting all the bounding rectangles of all the contours out of the image, selective filtering of the contours is done for classification and thus removing the unnecessary clutter like vertical lines, heading, numberings etc.</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">We get x, y, h, w from contours as properties. For filtering, 4 conditions were set:</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;"><b>h / w &lt; 3</b>, i.e. <i>Height / Width should be less than 3 </i>(This removes all the tall lines which have a lot more height than width).</p></li></ul><ul id="l3"><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;"><b>w / h &lt; 2</b>, i,e. <i>Width / Height should be less than 2 </i>(This removes all the horizontal lines and heading which have a lot more width than height).</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;"><b>h &gt; 20, </b>i.e. <i>h should be greater than 20px </i>(This removes smaller elements such as numbers or dots)</p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p style="display: inline;"><b>w&gt; 18, </b>i.e. <i>w should be greater that 18px </i>(This removes marks and numberings)</p></li></ul><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">And Voila, we ended up with the desired elements needed for the classification. These elements are cut out of the original binary images in order for the classification.</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span><img width="372" height="495" alt="image" src="Summer Research Intership 2022/Image_007.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">After this, we need to pass these bounded cutout elements in an array for further classification in the Deep CNN Model.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span><img width="340" height="39" alt="image" src="Summer Research Intership 2022/Image_008.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"> <b>PART B</b><b> - </b><span class="p">NOTATION CLASSIFICATION</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">A lot of approaches had to be considered for this part, since there was no dataset available for the hindi music notation, Devnagri Hindi Text Classification ended up being used and only selective elements, namely (<span class="s7">सा रे गा मा प ध</span>) were ended up getting passed to the model. These images are resized to 32px X 32px for uniformity, converted to binary as well and normalized.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Data Augmentation is also used to add random flips, random rotation and random zoom to counter overfitting of the model. in addition to the normal Deep CNN model with max pooling, batch normalization, and adding multiple dense layers.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;text-align: left;"><span><img width="371" height="611" alt="image" src="Summer Research Intership 2022/Image_009.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="48" height="1" alt="image" src="Summer Research Intership 2022/Image_010.png"/></span></p><h4 style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">PART C - <span class="p">NOTATION CLASSIFICATION</span></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">The image array from PART A is used here to classify the acquired images from value 0 to 6 and then using a dictionary convert to Sa, Re, Ga, Ma, Pa, Dha, Ni and Saa. This array is then converted to stream using music21 library and converted to MIDI file and used as audio file.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-top: 6pt;padding-left: 137pt;text-indent: -41pt;text-align: left;"><p style="display: inline;">E<span class="s2">XPERIMENTS</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="298" height="1" alt="image" src="Summer Research Intership 2022/Image_011.png"/></span></p><ul id="l4"><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><h4 style="display: inline;">Trackbars for customized Width, Height and Aspect</h4><p class="s4" style="padding-left: 41pt;text-indent: 0pt;text-align: left;"> <b>Ratio selection.</b></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 41pt;text-indent: 0pt;text-align: justify;">Since this project was mainly carried out in Jupyter Notebooks, I ended up hard coding the values required for this particular image since Jupyter doesn’t allow interactive windows. But it was brought to my attention that these height and width values may not work on different images</p><p style="padding-top: 3pt;padding-bottom: 1pt;padding-left: 41pt;text-indent: 0pt;text-align: justify;">with smaller or larger text. So a commercial version of this project works, say for React or Android, i tried for an interface to which includes a trackbar inorder for the correct texts to be recognized.</p><p style="padding-left: 42pt;text-indent: 0pt;text-align: left;"><span><img width="328" height="205" alt="image" src="Summer Research Intership 2022/Image_012.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 41pt;text-indent: -18pt;text-align: left;"><p class="s4" style="display: inline;"> <b>Iterative approach based on Pixel value threshold</b></p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 41pt;text-indent: 0pt;line-height: 93%;text-align: left;">I ended up with an Contour detected based approach, but previously I was set on an Iterative based approach/ Sliding Window approach. I manually handpicked points on top left of the text necessarily and counted the number of pixels used to show that piece of text , i.e <span class="s7">सा </span>took 342 pixels on average, <span class="s7">रे </span>took 275 pixels on average, <span class="s7">गा </span>313 pixels on average, <span class="s7">मा </span>took 361 on average, <span class="s7">प </span>took 256 and <span class="s7">ध </span>took</p><p style="padding-left: 41pt;text-indent: 0pt;text-align: left;">310. In short, in the 1600 X 1200 image, I planned to pick a 45 X 45 window on the top left and move it right and bottom and pass only those pixels that satisfy constraints based on these conditions. I was later made aware that my approach was fine but the implementation of it was somewhat naive. But by then, the contours based approach worked so I went with a contour based approach. This Pixels data with sliding window approach is still<a href="https://github.com/mickee00000/201951090_Research_Internship_2022/blob/main/part1.csv" style=" color: #1154CC; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;" target="_blank"> </a><span style=" color: #1154CC; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt;">here</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-top: 6pt;padding-left: 138pt;text-indent: -40pt;text-align: left;"><p style="display: inline;">C<span class="s2">ONCLUSION</span></p></li></ol><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">This project really made me aware of a lot more concepts in Machine Learning, Deep Learning and Image Manipulation. The best part about it is how different parts of this project do different things and it all comes together in the end ever so seamlessly.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 121pt;text-indent: 0pt;text-align: left;">R<span class="s2">EFERENCES</span></p><p class="s3" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">[1] <span style=" color: #000;">Sha P, Dong X. Research on Adolescents Regarding the Indirect Effect of Depression, Anxiety, and Stress between TikTok Use Disorder and Memory Loss. Int J Environ Res Public Health. 2021 Aug 21;18(16):8820. doi: 10.3390/ijerph18168820. PMID: 34444569; PMCID: PMC8393543.</span></p></body></html>
